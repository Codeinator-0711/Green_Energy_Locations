{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea of this notebook: train a ML model with the standard deviation of the atmospheric pressure to estimate if a location is suited for generating wind power\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../data/full_df.pqt')\n",
    "# drop useless cols\n",
    "data = data[['temp','dwpt', 'rhum', 'prcp','wspd', 'wpgt','pres','id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load or compute aggregated data\n",
    "std_data = data.groupby(['id']).agg('std')\n",
    "mean_data = pd.read_parquet('../data/all_means_df.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the na counts for each col\n",
    "nacounts = pd.concat([\n",
    "    data.loc[data[col].isna() == False].groupby(['id'])[col].count()\n",
    "    for col in data.columns\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only ids with sufficient data points\n",
    "mean_data_filtered = mean_data.loc[nacounts.wspd > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "# choose a cutoff percentile, if the mean wspd of a given location is greater it's suitable for wind power generation\n",
    "cutoff_percentile = .5\n",
    "cutoff_wspd = mean_data_filtered.sort_values('wspd',ascending=True).iloc[round(cutoff_percentile*len(mean_data_filtered))].wspd\n",
    "# add the col suitable \n",
    "mean_data_filtered.loc[:,'suitable'] = 0\n",
    "mean_data_filtered.loc[mean_data_filtered.wspd > cutoff_wspd,'suitable'] = 1\n",
    "# set the y data for the ml algorithm\n",
    "y = mean_data_filtered.suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the std as x data\n",
    "x = std_data.loc[y.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean of col, drop wind data to simulate missing data\n",
    "x.fillna(x.mean(),inplace=True)\n",
    "x.drop(['wspd','wpgt'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=.2,\n",
    "    stratify=y,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prognosegenauigkeit Decision Tree:\n",
      "\n",
      "Testdaten:\t 0.6521739130434783\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Random Forest:\n",
      "\n",
      "Testdaten:\t 0.7681159420289855\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Logistic Regression:\n",
      "\n",
      "Testdaten:\t 0.6086956521739131\n",
      "\n",
      "\n",
      "Prognosegenauigkeit K-Nearest Neighbors:\n",
      "\n",
      "Testdaten:\t 0.7101449275362319\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Neuronales Netz:\n",
      "\n",
      "Testdaten:\t 0.6956521739130435\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Gradient Tree Boosting:\n",
      "\n",
      "Testdaten:\t 0.7536231884057971\n"
     ]
    }
   ],
   "source": [
    "# run models\n",
    "\n",
    "##### Decision Tree\n",
    "\n",
    "# Fitting des Decision Tree Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\n",
    "decision_tree_train = DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", random_state=1)\n",
    "decision_tree_train.fit(xtrain, ytrain)\n",
    "\n",
    "# Der Decision Tree Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\n",
    "print(\"Prognosegenauigkeit Decision Tree:\\n\")\n",
    "print(\"Testdaten:\\t\", decision_tree_train.score(xtest, ytest))\n",
    "\n",
    "\n",
    "##### Random Forest\n",
    "\n",
    "# Fitting des Random Forest Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\n",
    "random_forest_train = RandomForestClassifier(random_state=1)\n",
    "random_forest_train.fit(xtrain, ytrain)\n",
    "\n",
    "# Der Random Forest Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\n",
    "print(\"\\n\\nPrognosegenauigkeit Random Forest:\\n\")\n",
    "print(\"Testdaten:\\t\", random_forest_train.score(xtest, ytest))\n",
    "\n",
    "\n",
    "##### Logistic Regression\n",
    "\n",
    "# Fitting des Logistic Regression Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\n",
    "logistic_regression_train = LogisticRegression(max_iter=1000)\n",
    "logistic_regression_train.fit(xtrain, ytrain)\n",
    "\n",
    "# Der Logistic Regression Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\n",
    "print(\"\\n\\nPrognosegenauigkeit Logistic Regression:\\n\")\n",
    "print(\"Testdaten:\\t\", logistic_regression_train.score(xtest, ytest))\n",
    "\n",
    "\n",
    "##### K-Nearest Neighbors\n",
    "\n",
    "# Fitting des K-Nearest Neighbors Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\n",
    "knn_train = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_train.fit(xtrain, ytrain)\n",
    "\n",
    "# Der K-Nearest Neighbors Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\n",
    "print(\"\\n\\nPrognosegenauigkeit K-Nearest Neighbors:\\n\")\n",
    "print(\"Testdaten:\\t\", knn_train.score(xtest, ytest))\n",
    "\n",
    "##### Neuronales Netz\n",
    "\n",
    "# Fitting des Neuronalen Netz Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\n",
    "neuronales_netz_train = MLPClassifier(max_iter=1000)\n",
    "neuronales_netz_train.fit(xtrain, ytrain)\n",
    "\n",
    "# Der Neuronales Netz Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\n",
    "print(\"\\n\\nPrognosegenauigkeit Neuronales Netz:\\n\")\n",
    "print(\"Testdaten:\\t\", neuronales_netz_train.score(xtest, ytest))\n",
    "\n",
    "##### Gradient Tree Boosting\n",
    "\n",
    "# Fitting des Gradient Boosting Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\n",
    "gradient_booosting_train = GradientBoostingClassifier()\n",
    "gradient_booosting_train.fit(xtrain, ytrain)\n",
    "\n",
    "# Der Gradient Boosting Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\n",
    "print(\"\\n\\nPrognosegenauigkeit Gradient Tree Boosting:\\n\")\n",
    "print(\"Testdaten:\\t\", gradient_booosting_train.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  8],\n",
       "       [ 8, 26]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ytest,random_forest_train.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the random forest since the accuracy is high and leads to some positive predictions\n",
    "# predict the suitability of all x-data\n",
    "# start by creating full x data\n",
    "full_x = std_data.fillna(std_data.mean()).drop(['wspd','wpgt'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate new algorithm, train it with all the data\n",
    "random_forest = RandomForestClassifier(random_state=1)\n",
    "random_forest.fit(x,y)\n",
    "full_x.loc[:,'prediction_suitable'] = random_forest.predict(full_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    831\n",
       "1    257\n",
       "Name: prediction_suitable, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_x.prediction_suitable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "full_x.to_csv('../data/wind_model_prediction_cutoff_0,5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7493435b741875e47357b1d4e2959b9ee7bbd8a014d8aa9e12beae2b4f843e2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
