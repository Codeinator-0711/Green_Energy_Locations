{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# idea of this notebook: train a ML model with the standard deviation of the atmospheric pressure to estimate if a location is suited for generating wind power\r\n",
    "# Imports\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from random import randint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "data = pd.read_parquet('../data/full_df.pqt')\r\n",
    "# drop useless cols\r\n",
    "data = data[['temp','dwpt', 'rhum', 'prcp','wspd', 'wpgt','pres','id']]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# load or compute aggregated data\r\n",
    "std_data = data.groupby(['id']).agg('std')\r\n",
    "mean_data = pd.read_parquet('../data/all_means_df.pqt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# get the na counts for each col\r\n",
    "nacounts = pd.concat([\r\n",
    "    data.loc[data[col].isna() == False].groupby(['id'])[col].count()\r\n",
    "    for col in data.columns\r\n",
    "],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# use only ids with sufficient data points\r\n",
    "mean_data_filtered = mean_data.loc[nacounts.wspd > 50]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# choose a cutoff percentile, if the mean wspd of a given location is greater it's suitable for wind power generation\r\n",
    "cutoff_percentile = .6\r\n",
    "cutoff_wspd = mean_data_filtered.sort_values('wspd',ascending=True).iloc[round(cutoff_percentile*len(mean_data_filtered))].wspd\r\n",
    "# add the col suitable \r\n",
    "mean_data_filtered.loc[:,'suitable'] = 0\r\n",
    "mean_data_filtered.loc[mean_data_filtered.wspd > cutoff_wspd,'suitable'] = 1\r\n",
    "# set the y data for the ml algorithm\r\n",
    "y = mean_data_filtered.suitable"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "G:\\Anaconda\\envs\\mapenv\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "G:\\Anaconda\\envs\\mapenv\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# use the std as x data\r\n",
    "x = std_data.loc[y.index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fill missing values with mean of col, drop wind data to simulate missing data\r\n",
    "x.fillna(x.mean(),inplace=True)\r\n",
    "x.drop(['wspd','wpgt'],inplace=True,axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# train test split\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\r\n",
    "    x,\r\n",
    "    y,\r\n",
    "    test_size=.2,\r\n",
    "    stratify=y,\r\n",
    "    random_state=1\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# import Algorithms\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# run models\r\n",
    "\r\n",
    "##### Decision Tree\r\n",
    "\r\n",
    "# Fitting des Decision Tree Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\r\n",
    "decision_tree_train = DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", random_state=1)\r\n",
    "decision_tree_train.fit(xtrain, ytrain)\r\n",
    "\r\n",
    "# Der Decision Tree Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\r\n",
    "print(\"Prognosegenauigkeit Decision Tree:\\n\")\r\n",
    "print(\"Testdaten:\\t\", decision_tree_train.score(xtest, ytest))\r\n",
    "\r\n",
    "\r\n",
    "##### Random Forest\r\n",
    "\r\n",
    "# Fitting des Random Forest Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\r\n",
    "random_forest_train = RandomForestClassifier(random_state=1)\r\n",
    "random_forest_train.fit(xtrain, ytrain)\r\n",
    "\r\n",
    "# Der Random Forest Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\r\n",
    "print(\"\\n\\nPrognosegenauigkeit Random Forest:\\n\")\r\n",
    "print(\"Testdaten:\\t\", random_forest_train.score(xtest, ytest))\r\n",
    "\r\n",
    "\r\n",
    "##### Logistic Regression\r\n",
    "\r\n",
    "# Fitting des Logistic Regression Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\r\n",
    "logistic_regression_train = LogisticRegression(max_iter=1000)\r\n",
    "logistic_regression_train.fit(xtrain, ytrain)\r\n",
    "\r\n",
    "# Der Logistic Regression Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\r\n",
    "print(\"\\n\\nPrognosegenauigkeit Logistic Regression:\\n\")\r\n",
    "print(\"Testdaten:\\t\", logistic_regression_train.score(xtest, ytest))\r\n",
    "\r\n",
    "\r\n",
    "##### K-Nearest Neighbors\r\n",
    "\r\n",
    "# Fitting des K-Nearest Neighbors Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\r\n",
    "knn_train = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\r\n",
    "knn_train.fit(xtrain, ytrain)\r\n",
    "\r\n",
    "# Der K-Nearest Neighbors Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\r\n",
    "print(\"\\n\\nPrognosegenauigkeit K-Nearest Neighbors:\\n\")\r\n",
    "print(\"Testdaten:\\t\", knn_train.score(xtest, ytest))\r\n",
    "\r\n",
    "##### Neuronales Netz\r\n",
    "\r\n",
    "# Fitting des Neuronalen Netz Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\r\n",
    "neuronales_netz_train = MLPClassifier(max_iter=1000)\r\n",
    "neuronales_netz_train.fit(xtrain, ytrain)\r\n",
    "\r\n",
    "# Der Neuronales Netz Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\r\n",
    "print(\"\\n\\nPrognosegenauigkeit Neuronales Netz:\\n\")\r\n",
    "print(\"Testdaten:\\t\", neuronales_netz_train.score(xtest, ytest))\r\n",
    "\r\n",
    "##### Gradient Tree Boosting\r\n",
    "\r\n",
    "# Fitting des Gradient Boosting Algorithmus auf den Trainingsdaten mit der Zielvariable 'Kauf' und den Eingabevariablen 'predictor_attributes'\r\n",
    "gradient_booosting_train = GradientBoostingClassifier()\r\n",
    "gradient_booosting_train.fit(xtrain, ytrain)\r\n",
    "\r\n",
    "# Der Gradient Boosting Algorithmus auf Basis der Trainingsdaten liefert folgende Prognosegenauigkeit\r\n",
    "print(\"\\n\\nPrognosegenauigkeit Gradient Tree Boosting:\\n\")\r\n",
    "print(\"Testdaten:\\t\", gradient_booosting_train.score(xtest, ytest))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prognosegenauigkeit Decision Tree:\n",
      "\n",
      "Testdaten:\t 0.7681159420289855\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Random Forest:\n",
      "\n",
      "Testdaten:\t 0.782608695652174\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Logistic Regression:\n",
      "\n",
      "Testdaten:\t 0.7971014492753623\n",
      "\n",
      "\n",
      "Prognosegenauigkeit K-Nearest Neighbors:\n",
      "\n",
      "Testdaten:\t 0.7681159420289855\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Neuronales Netz:\n",
      "\n",
      "Testdaten:\t 0.6956521739130435\n",
      "\n",
      "\n",
      "Prognosegenauigkeit Gradient Tree Boosting:\n",
      "\n",
      "Testdaten:\t 0.7536231884057971\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "confusion_matrix(ytest,random_forest_train.predict(xtest))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[39,  3],\n",
       "       [12, 15]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# choosing the random forest since the accuracy is high and leads to some positive predictions\r\n",
    "# predict the suitability of all x-data\r\n",
    "# start by creating full x data\r\n",
    "full_x = std_data.fillna(std_data.mean()).drop(['wspd','wpgt'],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "# instantiate new algorithm, train it with all the data\r\n",
    "random_forest = RandomForestClassifier(random_state=1)\r\n",
    "random_forest.fit(x,y)\r\n",
    "full_x.loc[:,'prediction_suitable'] = random_forest.predict(full_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "full_x.prediction_suitable.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    921\n",
       "1    167\n",
       "Name: prediction_suitable, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "# export data\r\n",
    "full_x.to_csv('../data/wind_model_prediction.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mapenv': conda)"
  },
  "interpreter": {
   "hash": "c7493435b741875e47357b1d4e2959b9ee7bbd8a014d8aa9e12beae2b4f843e2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}